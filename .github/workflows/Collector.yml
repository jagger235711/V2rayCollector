name: Collector
on:
  workflow_dispatch:
  schedule:
    - cron: "0 */12 * * *"

env:
  # è¾“å…¥æ–‡ä»¶é…ç½®
  RESOURCE_DIR: $GITHUB_WORKSPACE/resource
  # INPUT_SUBLIST: $GITHUB_WORKSPACE/resource/subList.csv
  # INPUT_CHANNELS: $GITHUB_WORKSPACE/resource/channels.csv
  
  # è¾“å‡ºç›®å½•é…ç½®
  RESOULTS_DIR: $GITHUB_WORKSPACE/results
  # OUTPUT_MIXED: $GITHUB_WORKSPACE/results/mixed.txt
  # OUTPUT_TESTED: $GITHUB_WORKSPACE/results/mixed_tested.json
  
  # å·¥å…·è·¯å¾„é…ç½®

  TOOLS_DIR: $GITHUB_WORKSPACE/tool
  # SPEEDTEST_TOOL: $GITHUB_WORKSPACE/tool/speedTest_singtools/singtools
  # SPEEDTEST_CONFIG: $GITHUB_WORKSPACE/tool/speedTest_singtools/config.json

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Delete old Releases and Workflows
        uses: ophub/delete-releases-workflows@main
        with:
          gh_token: ${{secrets.GITHUB_TOKEN}}
          delete_releases: true
          releases_keep_latest: 3
          delete_tags: true
          delete_workflows: true
          workflows_keep_day: 3

      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Cleanup results directory
        run: |
          rm -rf ${{ env.RESOULTS_DIR }}/*
          mkdir -p ${{ env.RESOULTS_DIR }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt --cache-dir ~/.cache/pip

      - name: Deduplicate URLs
        run: |
          python deduplicate.py ${{ env.RESOURCE_DIR }}/subList.csv ${{ env.RESOURCE_DIR }}/subList.csv
          echo "å»é‡å®Œæˆï¼Œå¤„ç†äº† $(wc -l < ${{ env.RESOURCE_DIR }}/subList.csv) ä¸ªURL"
          python deduplicate.py ${{ env.RESOURCE_DIR }}/channels.csv ${{ env.RESOURCE_DIR }}/channels.csv
          echo "å»é‡å®Œæˆï¼Œå¤„ç†äº† $(wc -l < ${{ env.RESOURCE_DIR }}/channels.csv) ä¸ªURL"
          echo "å¤‡ä»½æ–‡ä»¶:"
          ls -la ${{ env.RESOURCE_DIR }}/*.bak

      - name: Run Scrapy spider
        run: |
          scrapy crawl telegram_crawler

      - name: Cache Docker images
        uses: actions/cache@v3
        with:
          path: ~/.docker/cache
          key: ${{ runner.os }}-docker-${{ hashFiles('**/Dockerfile') }}
          restore-keys: |
            ${{ runner.os }}-docker-

      - name: Start subconverter and process URLs (å¹¶å‘ç‰ˆæœ¬)
        run: |
          set -e

          echo "=== ğŸ³ å®¹å™¨æŒ‚è½½è°ƒè¯•å¼€å§‹ ==="
          CONTAINER_NAME="subconverter_container"
          CONTAINER_PORT=25500
          HOST_PORT=25500
          IMAGE_NAME="asdlokj1qpi23/subconverter:latest"
          RESULT_DIR="${{ env.RESOULTS_DIR }}"
          RESOURCE_FILE="${{ env.RESOURCE_DIR }}/subList.csv"
          RESULT_FILE="${RESULT_DIR}/mixed_base64.txt"
          MAX_PER_BATCH=5
          MAX_CONCURRENT=5  # å¹¶å‘å¤„ç†çš„æœ€å¤§æ‰¹æ¬¡æ•°

          docker run -d --name $CONTAINER_NAME --restart=always \
            -v "$RESULT_DIR:/subconverter/results" \
            -p ${HOST_PORT}:${CONTAINER_PORT} \
            $IMAGE_NAME

          echo "ç­‰å¾… subconverter å¯åŠ¨..."
          for i in {1..30}; do
            if curl -s http://localhost:${HOST_PORT} >/dev/null; then
              echo "âœ… æœåŠ¡å·²å°±ç»ª"
              break
            fi
            sleep 1
            if [ $i -eq 30 ]; then
              echo "âŒ å¯åŠ¨å¤±è´¥"
              exit 1
            fi
          done

          if [ ! -f "$RESOURCE_FILE" ]; then
            echo "âŒ èµ„æºæ–‡ä»¶ä¸å­˜åœ¨: $RESOURCE_FILE"
            exit 1
          fi

          echo "è¯»å–èµ„æºåˆ—è¡¨..."
          mapfile -t links < "$RESOURCE_FILE"
          total=${#links[@]}
          echo "" > "$RESULT_FILE"
          TMP_BATCH_DIR=$(mktemp -d)

          process_batch() {
            local index=$1
            shift
            local batch=("$@")
            local batch_url
            batch_url=$(IFS='|'; echo "${batch[*]}")
            local request_url="http://localhost:${HOST_PORT}/sub?target=mixed&url=$batch_url"
            local temp_file="${TMP_BATCH_DIR}/batch_${index}.txt"
            
            echo "ğŸ”§ æ‰¹æ¬¡ $index è¯·æ±‚: $request_url"
            
            # é‡è¯•æœºåˆ¶ - æœ€å¤š3æ¬¡å°è¯•
            local retry_count=0
            local max_retries=3
            local success=false
            
            while [ $retry_count -lt $max_retries ] && [ "$success" = false ]; do
              if curl -fsSL "$request_url" -o "$temp_file"; then
                echo "âœ… æ‰¹æ¬¡ $index å®Œæˆ (å°è¯• $((retry_count+1)))"
                success=true
              else
                retry_count=$((retry_count+1))
                if [ $retry_count -lt $max_retries ]; then
                  echo "âš ï¸ æ‰¹æ¬¡ $index è¯·æ±‚å¤±è´¥ (å°è¯• $retry_count/$max_retries)ï¼Œç­‰å¾…1ç§’åé‡è¯•..."
                  sleep 1
                else
                  echo "âŒ æ‰¹æ¬¡ $index è¯·æ±‚å¤±è´¥ (å°è¯• $retry_count/$max_retries)"
                  rm -f "$temp_file"
                fi
              fi
            done
          }

          echo "=== ğŸš€ å¼€å§‹å¹¶å‘å¤„ç† ==="
          job_count=0
          batch_index=1

          for ((i = 1; i < total; i += MAX_PER_BATCH)); do
            batch=("${links[@]:i:MAX_PER_BATCH}")
            process_batch "$batch_index" "${batch[@]}" &
            job_count=$((job_count + 1))
            batch_index=$((batch_index + 1))

            if (( job_count >= MAX_CONCURRENT )); then
              wait
              job_count=0
            fi
          done

          wait  # ç­‰å¾…æ‰€æœ‰å‰©ä½™åå°ä»»åŠ¡å®Œæˆ

          echo "ğŸ§© åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡ç»“æœ"
          sort -V "${TMP_BATCH_DIR}"/batch_*.txt >> "$RESULT_FILE"
          rm -rf "$TMP_BATCH_DIR"

          echo "ğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆï¼Œç»“æœæ–‡ä»¶: $RESULT_FILE"

      - name: Decode base64 and append to mixed.txt
        run: |
          # echo "å·¥ä½œè·¯å¾„: $GITHUB_WORKSPACE"
          # echo "å½“å‰è·¯å¾„: $(pwd)"
          # echo "----------------"
          # ls -R $GITHUB_WORKSPACE
          # echo "----------------"
          base64 -d ${{ env.RESOULTS_DIR }}/mixed_base64.txt >> ${{ env.RESOULTS_DIR }}/mixed.txt

      - name: Clean mixed.txt content
        run: |
          if [ ! -f "${{ env.RESOULTS_DIR }}/mixed.txt" ]; then exit 1; fi
          cat "${{ env.RESOULTS_DIR }}/mixed.txt" | sed 's/^[ \t]*//;s/[ \t]*$//' | sed '/^$/d' > "${{ env.RESOULTS_DIR }}/mixed.txt.tmp"
          mv "${{ env.RESOULTS_DIR }}/mixed.txt.tmp" "${{ env.RESOULTS_DIR }}/mixed.txt"
          echo "æ¸…ç†åç»Ÿè®¡ï¼š$(wc -l ${{ env.RESOULTS_DIR }}/mixed.txt) è¡Œ $(wc -c ${{ env.RESOULTS_DIR }}/mixed.txt) å­—èŠ‚"

      - name: Speedtest
        run: |
          if [ ! -f "${{ env.RESOULTS_DIR }}/mixed.txt" ]; then exit 1; fi
          chmod +x ${{ env.TOOLS_DIR }}/speedTest_singtools/singtools
          ${{ env.TOOLS_DIR }}/speedTest_singtools/singtools test -i ${{ env.RESOULTS_DIR }}/mixed.txt -c ${{ env.TOOLS_DIR }}/speedTest_singtools/config.json -o ${{ env.RESOULTS_DIR }}/mixed_tested.json -e fatal -f ""
          if [ ! -f "${{ env.RESOULTS_DIR }}/mixed_tested.json" ]; then exit 1; fi

      - name: Convert to mixed with base64encode
        run: |
          if [ ! -f "${{ env.RESOULTS_DIR }}/mixed_tested.json" ]; then exit 1; fi
          full_url="http://localhost:25500/sub?target=mixed&url=/subconverter/results/mixed_tested.json"
          echo "æ­£åœ¨è¯·æ±‚: $full_url"
          if ! curl -v -o ${{ env.RESOULTS_DIR }}/mixed_tested.txt "$full_url"; then
            echo "curl failed: $(docker exec subconverter_container ls -l /subconverter/results)"
            exit 1
          fi
          if [ ! -s "${{ env.RESOULTS_DIR }}/mixed_tested.txt" ]; then exit 1; fi

      - name: Commit Changes
        run: |
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Actions"
          git pull origin main
          git add ${{ env.RESOULTS_DIR }}/*
          git add ${{ env.RESOURCE_DIR }}/*
          git commit -m "âœ”ï¸ $(date '+%Y-%m-%d %H:%M:%S') Collected" || echo "No changes to commit"

      - name: Push Changes
        uses: ad-m/github-push-action@master
        with:
          branch: ${{ github.ref }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
